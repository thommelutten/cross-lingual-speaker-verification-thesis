{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_dataset_into_train_and_test_pandaframes(metadata_p):\n",
    "    metadata = pd.read_csv(metadata_p, delimiter='\\t')\n",
    "    train_pf = metadata.loc[metadata['Set'] == 'dev']\n",
    "    test_pf = metadata.loc[metadata['Set'] == 'test']\n",
    "    return train_pf, test_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_audio_files_to_pf(pandaframe, audio_path):\n",
    "    coefficients_path = \"rpcc/\"\n",
    "    list_with_audio_files = []\n",
    "    \n",
    "    for index, row in pandaframe.iterrows():\n",
    "        list_of_audio_files = find_audio_files(row['VoxCeleb1 ID'], audio_path)\n",
    "        for audio in list_of_audio_files:\n",
    "            audio_path_parts = str(audio).split('/')\n",
    "            list_with_audio_files.append([row['VoxCeleb1 ID'], row['Gender'], row['Nationality'], row['Set'], '/'.join(audio_path_parts[4:])])\n",
    "    return pd.DataFrame(list_with_audio_files, columns = ['VoxCeleb1 ID', 'Gender', 'Nationality', 'Set', 'Audio Path'])\n",
    "        \n",
    "def find_audio_files(speaker_id, audio_path):\n",
    "    audio_path = Path(audio_path)\n",
    "    return [f for f in audio_path.glob(\"{}/**/*.wav.npy\".format(speaker_id)) if f.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = \"voxceleb1_metadata.csv\"\n",
    "dev_audio_path = \"processed/Processed/vox1_dev_wav/wav\"\n",
    "test_audio_path = \"processed/Processed/vox1_test_wav/wav\"\n",
    "train_pf, test_pf = split_dataset_into_train_and_test_pandaframes(metadata_path)\n",
    "train_pf_with_audio_files = append_audio_files_to_pf(train_pf, dev_audio_path)\n",
    "test_pf_with_audio_files = append_audio_files_to_pf(test_pf, test_audio_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VoxCeleb1 ID                              id10002\n",
      "Gender                                          m\n",
      "Nationality                                 India\n",
      "Set                                           dev\n",
      "Audio Path      id10002/cMGEuZ1zqXk/00004.wav.npy\n",
      "Name: 80, dtype: object\n",
      "Found 0 with less than 40 Frames, removing them from train set\n"
     ]
    }
   ],
   "source": [
    "frames_lower_than_40 = []\n",
    "for index, row in train_pf_with_audio_files.iterrows():\n",
    "    rpcc = np.load(\"{}/{}\".format(dev_audio_path,row['Audio Path']))\n",
    "        \n",
    "    if len(rpcc[1]) < 40:\n",
    "        frames_lower_than_40.append(index)\n",
    "        \n",
    "print(\"Found {} with less than 40 Frames, removing them from train set\".format(len(frames_lower_than_40)))\n",
    "\n",
    "train_pf_with_audio_files = train_pf_with_audio_files.drop(index=frames_lower_than_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 with less than 40 Frames, removing them from train set\n"
     ]
    }
   ],
   "source": [
    "frames_lower_than_40 = []\n",
    "for index, row in test_pf_with_audio_files.iterrows():\n",
    "    full_audio_path = \"{}/{}\".format(test_audio_path, row['Audio Path'])\n",
    "   # print(full_audio_path)\n",
    "    rpcc = np.load(full_audio_path)\n",
    "        \n",
    "    if len(rpcc[1]) < 40:\n",
    "        frames_lower_than_40.append(index)\n",
    "\n",
    "print(\"Found {} with less than 40 Frames, removing them from train set\".format(len(frames_lower_than_40)))\n",
    "\n",
    "test_pf_with_audio_files = test_pf_with_audio_files.drop(index=frames_lower_than_40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_speaker_ids = (train_pf_with_audio_files['VoxCeleb1 ID'].unique()).tolist()\n",
    "validate_speaker_ids = (test_pf_with_audio_files['VoxCeleb1 ID'].unique()).tolist()\n",
    "speaker_list_ids = train_speaker_ids + validate_speaker_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_id_to_index = {}\n",
    "speaker_index_to_id = {}\n",
    "for idx, speaker_id in enumerate(speaker_list_ids):\n",
    "    speaker_id_to_index[speaker_id] = idx\n",
    "    speaker_index_to_id[idx] = speaker_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxCelebDataset(data.Dataset):\n",
    "    def __init__(self, pandaframe, targets, root_dir):\n",
    "        self.dataset = pandaframe\n",
    "        self.targets = targets\n",
    "        self.root_dir = root_dir\n",
    "        self.len = len(pandaframe)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        speaker = self.dataset.iloc[index]\n",
    "        path_to_rpcc = \"{}/{}\".format(self.root_dir, speaker['Audio Path'])\n",
    "        rpcc = np.load(path_to_rpcc)\n",
    "        #return \n",
    "        return torch.Tensor(rpcc[:,0:40]), speaker['VoxCeleb1 ID']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VoxCelebDataset(train_pf_with_audio_files, speaker_id_to_index, dev_audio_path)\n",
    "test_dataset = VoxCelebDataset(test_pf_with_audio_files, speaker_id_to_index, test_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "train_dataloader = data.DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_dataloader = data.DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "# data, target = next(iter(dataloader))\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, coefficients, hidden_dim, speaker_size, label_size, batch_size):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm = nn.LSTM(coefficients, hidden_dim)\n",
    "        self.hidden2label = nn.Linear(hidden_dim, speaker_size)\n",
    "        self.hidden = self. init_hidden()\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "\n",
    "#         self.l_out = nn.Linear(in_features=3000,\n",
    "#                                out_features=speaker_size)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda()),\n",
    "                autograd.Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda()))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #x = sentence.view(len(sentence), self.batch_size , -1)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
    "        y  = self.hidden2label(lstm_out[-1])\n",
    "        #log_probs = F.log_softmax(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(coefficients=40, hidden_dim=4, speaker_size=len(speaker_index_to_id),label_size=len(speaker_index_to_id), batch_size=batch_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, training loss: 7.06932917103001, validation loss: 11.386523908498337\n",
      "Epoch 1, training loss: 7.089495586082289, validation loss: 14.766786030360631\n",
      "Epoch 2, training loss: 7.107071005584573, validation loss: 17.816991494626414\n",
      "Epoch 3, training loss: 7.117496122669356, validation loss: 20.12984003339495\n",
      "Epoch 4, training loss: 7.118825798316858, validation loss: 22.37396177953603\n",
      "Epoch 5, training loss: 7.116270257709967, validation loss: 24.966650359484614\n",
      "Epoch 6, training loss: 7.1132678709819, validation loss: 27.1500771970165\n",
      "Epoch 7, training loss: 7.112040803507822, validation loss: 30.160870999706034\n",
      "Epoch 8, training loss: 7.1081543215666345, validation loss: 32.6421949814777\n",
      "Epoch 9, training loss: 7.118056040445109, validation loss: 34.39792337222975\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "training_loss, validation_loss = [], []\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    epoch_training_loss = 0\n",
    "    epoch_validation_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for idx, (data_train, targets_train) in enumerate(train_dataloader):\n",
    "        model.batch_size = len(data_train)\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        targets_idx = [speaker_id_to_index[speaker_id] for speaker_id in targets_train]\n",
    "        \n",
    "        targets_idx = torch.LongTensor(targets_idx)\n",
    "        \n",
    "        data_train = data_train.cuda()\n",
    "        targets_idx = targets_idx.cuda()\n",
    "        #print(data.shape)\n",
    "        data_train = data_train.permute(1,0,2)\n",
    "        #print(data.shape)\n",
    "        outputs = model.forward(data_train)\n",
    "        loss = criterion(outputs, targets_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_training_loss += loss.cpu().detach().numpy()  \n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for idx, (data_validate, targets_validate) in enumerate(test_dataloader):\n",
    "        \n",
    "        model.batch_size = len(data_validate)\n",
    "        model.hidden = model.init_hidden()\n",
    "        #print(data.shape)\n",
    "        data_validate = data_validate.permute(1,0,2)\n",
    "        data_validate = data_validate.cuda()\n",
    "        \n",
    "        \n",
    "        outputs = model.forward(data_validate)\n",
    "        \n",
    "        targets_idx = [speaker_id_to_index[speaker_id] for speaker_id in targets_validate]\n",
    "        targets_idx = torch.LongTensor(targets_idx)\n",
    "        targets_idx = targets_idx.cuda()\n",
    "        \n",
    "        loss = criterion(outputs, targets_idx)\n",
    "        \n",
    "        # Update loss\n",
    "        epoch_validation_loss += loss.cpu().detach().numpy()    \n",
    "    \n",
    "    training_loss.append(epoch_training_loss/len(train_dataloader))\n",
    "    validation_loss.append(epoch_validation_loss/len(test_dataloader))\n",
    "\n",
    "    print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = pd.read_csv('voxceleb_verification_test.csv', delimiter=' ', names=['Target', 'Trial file 1', 'Trial file 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target                                      1\n",
      "Trial file 1    id10270/x6uYqmx31kE/00001.wav\n",
      "Trial file 2    id10270/8jEAjG6SegY/00008.wav\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(trials.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_results = pd.DataFrame(columns=['Targettype', 'Actual target', 'audio_file', 'Score for actual'])\n",
    "\n",
    "for index, trial in trials.iterrows():\n",
    "    trial_rpcc = np.load(\"{}/{}.npy\".format(test_audio_path, trial['Trial file 2']))\n",
    "#trial_rpcc = np.load(\"{}/{}.npy\".format(test_audio_path, trial['Trial file 2']))\n",
    "    \n",
    "    trial_rpcc = torch.tensor(trial_rpcc[:,:40]).unsqueeze(0)\n",
    "\n",
    "    model.batch_size = len(trial_rpcc)\n",
    "    model.hidden = model.init_hidden()\n",
    "\n",
    "\n",
    "    trial_rpcc = trial_rpcc.permute(1,0,2)\n",
    "\n",
    "    trial_rpcc = trial_rpcc.cuda()\n",
    "\n",
    "    output = model.forward(trial_rpcc)\n",
    "    \n",
    "    \n",
    "    _, result = torch.max(output,1)\n",
    "\n",
    "    result = result.cpu().detach().numpy()[0]\n",
    "    speaker_result = speaker_index_to_id[result]\n",
    "    \n",
    "    trial_actual_target = str(trial['Trial file 1']).split('/')[0]\n",
    "    speaker_actual = speaker_id_to_index[trial_actual_target]\n",
    "    \n",
    "    result_actual = output.cpu().detach().numpy()[0][speaker_actual]\n",
    "    \n",
    "    new_row = {'Targettype': trial['Target'], 'Actual target': trial_actual_target, 'audio_file': trial['Trial file 2'], 'Score for actual': result_actual}\n",
    "    #print(new_row)\n",
    "    \n",
    "    trials_results = trials_results.append(new_row, ignore_index=True)\n",
    "\n",
    "# print(speaker_result)\n",
    "# print(trial_actual_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Targettype Actual target                     audio_file  \\\n",
      "0              1       id10270  id10270/8jEAjG6SegY/00008.wav   \n",
      "1              0       id10270  id10300/ize_eiCFEg0/00003.wav   \n",
      "2              1       id10270  id10270/GWXujl-xAVM/00017.wav   \n",
      "3              0       id10270  id10273/0OCW1HUxZyg/00001.wav   \n",
      "4              1       id10270  id10270/8jEAjG6SegY/00022.wav   \n",
      "...          ...           ...                            ...   \n",
      "37715          0       id10309  id10302/K2_D_tFdAgY/00036.wav   \n",
      "37716          1       id10309  id10309/0b1inHMAr6o/00010.wav   \n",
      "37717          0       id10309  id10289/8l5ZnDf-FUA/00012.wav   \n",
      "37718          1       id10309  id10309/rxnN8thYzEQ/00017.wav   \n",
      "37719          0       id10309  id10296/Y-qKARMSO7k/00001.wav   \n",
      "\n",
      "       Score for actual  \n",
      "0            -15.295091  \n",
      "1            -15.295091  \n",
      "2            -15.295091  \n",
      "3            -15.295091  \n",
      "4            -15.295091  \n",
      "...                 ...  \n",
      "37715        -16.077700  \n",
      "37716        -16.077700  \n",
      "37717        -16.077700  \n",
      "37718        -16.077700  \n",
      "37719        -16.077700  \n",
      "\n",
      "[37720 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(trials_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3606224060058594\n",
      "0.6073827743530273\n",
      "0.4948730145162692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0454391390>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9b3/8dcnCSRACCCCgoAogoCiiGhdcV9r1VatVu3totdbq7Zqe3tte3tvr78u2lartdrWYl3aat0VbeuGC64oICiLArIom6DsIIEkn98fn+/IdCZAICQThvfz8chjJuec73e+M5mcz/mux9wdERGRbCWFLoCIiLQ8Cg4iIpJHwUFERPIoOIiISB4FBxERyVNW6AJsDTvuuKP37t270MUQEdmmjB079iN371LfvqIIDr1792bMmDGFLoaIyDbFzGZvaJ+alUREJI+Cg4iI5FFwEBGRPAoOIiKSR8FBRETyKDiIiEgeBQcREclTFPMcttSCZWu4e/QGh/lKA+zToyPHDtyp0MUQka1suw4OHy5fw03PTS90MbZZ7rBTVbmCg0gR2q6Dw749OzLz558tdDG2WT/9+2T+8tr7hS6GiDQB9TnIFqssb8Un62qpqa0rdFFEZCtTcJAt1r4iKp4rq2sKXBIR2doUHGSLVabgsGKNgoNIsVFwkC1WpeAgUrQUHGSLVZa3AtSsJFKMFBxki7X/tOawrsAlEZGtTcFBtlh7NSuJFC0FB9lin3ZIq1lJpOgoOMgWq6qIPgc1K4kUHwUH2WLlZSWUlRgr1awkUnQUHGSLmRntK8rU5yBShBQcpFEqK8o0lFWkCCk4SKO0L2+lPgeRIqTgII1SWVHGcjUriRQdBQdplKqKMnVIixQhBQdplPYVrVhRrWYlkWKj4CCNUlmumoNIMVJwkEbJDGV190IXRUS2IgUHaZTKijJq6pzqGt0NTqSYKDhIo7RPS2gs13BWkaKi4CCN0r483SpU/Q4iRUXBQRpFy3aLFCcFB2mUynIFB5FipOAgjZLpc1ipuQ4iRUXBQRol06ykJTREiouCgzRKJjioQ1qkuCg4SKOoz0GkOCk4SKOUlZbQplWp+hxEioyCgzSa7gYnUnwUHKTRKivKWKG7wYkUFQUHabT2Fa1UcxApMgoO0mjty8t0q1CRIqPgII3WXneDEyk6Cg7SaOqQFik+Cg7SaJXlrVipDmmRoqLgII3WvqKMldU11NbpbnAixULBQRots4TGqrWqPYgUCwUHaTTd00Gk+Cg4SKNVlqdluxUcRIqGgoM02vqag+Y6iBQLBQdptEo1K4kUHQUHabSqTHDQcFaRotGg4GBm3zaziWY2ycwuT9v2NbNXzextM3vMzKoamnZj6c2stZndnrZPMLMjt8L7lCaUuVWompVEiscmg4OZ7Q38O3AgsC9wipn1BYYDV7n7IOBh4D83Iy0bSf/vAGn7ccB1ZqYaTguWueGPOqRFikdDTroDgBXA68AEYC3w+bT9GjN7G/gScNZmpGUj6fcG9kjbXwA6AEM3+51Js2nbupQSU5+DSDFpSHBYAwwBTgQOAg4hTuAOPJau8D8GdtuMtGwkfStgV2A/4AvA7imPf2FmF5nZGDMbs2jRoga8DWkqZkZleZmW0BApIg0JDhXAaGAE8HdgKnEiN+BIMxsLzAVKNyMtG0n/HFADjAGuAz4hah//wt1vdfeh7j60S5cuDXgb0pTaV7RiufocRIpGQ4LDRKA/0AbYEegH1ALTgV5Aa+BU4mTf0LRsJP3otH1v4AQiULyZm7FqDi2Llu0WKS4NCQ6lxAl9DXEF34640m+dfl8LlBMn8YamZSPpDwBWEgHlHKKZaU1uxqo5tCxatlukuJQ14JgBxFV9ORFMJgNtib6A5USH8SfpGMzsWOB+YA5QndLkpgXoC9Sl528DmTP8BUAVEThWAE8QHdIztuwtSnOoLC9j0crqQhdDRLaShjYrrQIOJ0YU9QMWAdOIoLAD0URUmoap/hw4PWuIaqvctGmI6zrgfKAybc80Kw0kgsYUYAlwNPBObqHUrNSytK9opWYlkSKyyZqDu08xs1qiJlALPEMEi6nA6cTV/Sdp3+eJk/sjZjYHWECc/HPTDgAWA/eml1nK+g7pKqJG0p8IXmXArHrKdStwK8DQoUN1I4ECU7OSSHFp0OQyd+/n7m3cvZJoApoG3EH0E/QCDkt57U1c9f8ya4iq15N2DdGM1ItoliojAgwpz5vcvQ1wV8q3X26ZVHNoWSoryrR8hkgRaejyGV3TYy9i7sE9QFfWD1N9AnifjQxxzUlbAYxj/RDXtURNAqIJ6fSUfpe0La+/QR3SLUtVRSvW1tRRXVO76YNFpMVrSIc0wINm1pnoJ7jE3ZeYWR9iUlst0bS0AxEgZqXtM4khqqVmNjkn7USiltE65e9E3wZEP8Nn0jaAD909Ezg+ZWYXARcB9OrVq8FvWJpGZgmNU296mZKS+kY1Q4c2Zfzhy0Pp0KZVcxZNRLZAg4KDux9ez+a7ga8R/QpriVnMc4kaxRSiVtIBWOvuA3PSlhLDVXPTktLflfJ+jvWjmHLLpD6HFuTIPbvw2UHdWFtbV+/+tTV1vDB1EU9OXMAXD+jZzKUTkc3V0JpDfTY2xPV9oCMxUqlVWo31PqIDugzoDnQClpE/xHUfYE9ijsNyoH0jyijNZNfO7bj5vLxVTj7l7hx27XM89+5CBQeRbUBjVjvd0BDXt4CbgIVEX0E1cAoxAa4CuIpYa2k58HhOWogaRTkxGmossC5rJddPqUN622Jm7NuzA1PmLy90UUSkAbY4OLj7FKK/YQ7RuZwZpvo08CuiZrE6/bwAfAUYDIxKaVcCV+akBfgDUaOoAwal/DMruWa/vjqktzF77lTF7MWrufK+8Tz7zoeFLo6IbESj7pNQ3xBXd/8hEQQ+JpqP2gJfJ/ofJgFT0nLcnwCrcoa4AtxJBIZyImD0BXrnvrZqDtueo/t3ZbfO7Xhi4gKue2pqoYsjIhvRqOBQ3xDXtK2UGJ3Uieh/aEVMhitl/XpKs4mRTNlDXCGanowIHqXpsU/ua6vmsO0Z1KMDz373SP5jWB8mzVvO42/NK3SRRGQDGtMhDfUPcf028F9EH8PvgO8DzwM7E7OeW7u7m9kEIhA8lkmb8vwhUctYSHRUG9H/IEXivIN68ccXZ/Cf97/F+PeX0rqshPMP2pXuHdsUumgikpj71h8FamYDiM7mA4HOxF3g/kw0N/2UCAijgb3TTOjc9D8kgko1EcB6ZwWPzDHZ8xz2nz179lZ/H9J0Xp+5mEvvHsfK6hpWr61lh3atueNrB9B/5ypal+musCLNwczGunu9d9pskuCQXnQhcQ8HJ+Y9PE00LX2dqA0sSa+/g5l1B4a7+8lm1gn4iFhGoy49Xuzuf9nQaw0dOtTHjBnTJO9Dmt7vX3iPa/4ZaysO6FbFjecMpt9OGsEs0tQ2Fhya5BItrbq6kAgG5UQT01Ki5nC0u5cQI5o+AXD3ee5+ckp+LDHCaZdUq7iEmHEtReobR/ThkUsO5dozBrFw+Ro+d9NL3PHyTJrqwkVENq2p6u8DgPHuvpoYsVSZtvcHRplZCbA/9d897n0ioLQxMwOOIWoeUsQG9+zI2Qf04onLh3HoHjvy48cm85Xb32Dh8rz7PIlIM2jKPoexwAdEv0Ep8CwxGa41MUT1A+BQ4l4QrYBadx9oZvumtCVEk9RY4HB3r855DfU5FCl35y+j3+enf59M29ZlnLl/D44buBMH9N6h0EUTKSrN3qyUJrldRgSBpcCLRN/BScRchxXE6qtlRKf1XsC8NBN6OPDF1PR0JbArsRBf7mtoKGuRMjO+fNCuPH7ZYezVvYo7Xp7FWb9/lT+/OqvQRRPZbjTZsBB3v83dh7j7MGI57mnu/o67H+/u+wPvAovdfbW71xCzqD9PrKv0cMrmoVTGA5uqnNJy7dG1PX++4DOM/9/jOHbATvzo0UncOuq9QhdLZLvQ2HkOG2RmXd19YdYkt4OztpUQfQkVZjaFaD5qQwx/nQW8a2aridFOO7B+Oe/s/LVk93aibesyfnf+EK64dzw/+8c7rKqu5fJj+xJdUiLSFJosOLCBCXJmdknaP4poXlpD9EvsRnRcVwN7pGPWArj7E7mZa8nu7Uur0hJuPGc/2rQq5caR0xj/wVIO3aMz++/aib26d6CiVemmMxGRBmuy4FDfPSDc/UbgRgAzOyttuzD9/gKxzPdi4Gvufq+ZXQH8d1OVUbYtpSXGtWfsQ/eObXj4zbm8MDXW1GpdWsIBu3XiyuP6sf+u6rQW2RqabBLcJl94w7Oo7yTWWbK0/X/d/Zf1pNdope3cohXVjHt/CeNmL+HhN+eycEU1Jw/ame+d0J/eO7YrdPFEWryCzJBuCDObCvQklv5+jhjWOoRYiXUlsbZSpbsfu7F8NENaVlXX8McXZ/CHF2ZQ584NZw/mxL13Vr+EyEY0+1DWzXAz8B6xQmsFsWx35v7Rq4mlujU7WjapXXkZlx/bj+f/80j6dKnk4r+O4/RbXuHZdz7UTGuRLVCw4JCW2PgG0ax0ChEERhOd1CPcfTDwHTQ7WjbDTlUVPHLJoVzzhUF8vLKar98xhlN/+zLj3l+y6cQi8qlC9jmcRdxOdDExomkcEQj6A8cTNwtaA3zT3cduLC81K0l91tXW8fC4udw4chqLVlbzyzP34bTBuxS6WCItRkttVppI3Ef6cOBgIij0JNZWqiE6pCcR96HOozvByaa0Ki3hiwf05PHLDmNwj458+2/j+f0LmkQn0hAFCw5piY2xxD2iF7F+ee57iL6HNsCRRO2ivvRaPkMapFO71vz5wgP53L7dueaf73DjM9PUDyGyCYXucxhEDFftQKzeuhS4ABjp7n2B+4ETClVGKR7lZaXccPZgzhjSg18/M5X/evAtlq5eW+hiibRYTTlDelM+XdY7LbGRWdb7C0RTE8TCfeWFKJwUn9IS45dn7kO3DhXc8vx0Hho3lyuO68c3j+yjIa8iOQo9Ca6+Zb3/g1iUz4l1loa5e8d60msSnGyxyfOWc91T7zLynYXs1b2Kbx/Tl2MH7ERJiYKEbD9a8iS4C4g7vWUmvH1CLJ3RMeuYJe7eaWP5aLSSbIm6OueOV2Zx+ysz+WDxJwzu2ZG7LjiQqopWhS6aSLNoqaOV6l3WG/jQzLoBpMeFhSyjFK+SEuPrh+3Gc985kl+csQ8T5y7j+OtH8c+35xe6aCIFV8g+B8zsR8A5qRzdgH7EfaZHm1k1MUv6scKVULYHZWnIa+8d2/H/Hp/MxX8dx1F7duHaM/eha/uKQhdPpCAKOVppF+CHqQxriElwJwJdifkPECOZdBknzeLA3XbgwYsP4aqT+vPKex9z8o0v8czkDwtdLJGCKPTaSouI+0jvT/Q7zAcOAwanoaxnEbOlRZpF67ISvnFEH0Zcehg7VrbmwrvGcOV941m2el2hiybSrAo5CW4u8CtiRvR8YBkxemlpum0oxAS5etc70AxpaUp77tyeEZcexreO3oNHx8/j+Bte4Nl3VIuQ7Uchm5U6AacRd4DrDrQDTqrn0HqHU2mGtDS11mUlXHn8njzyzUPp2KY1X79jDN97YAIr1qgWIcWvkM1KxwIz3X2Ru68DHiJWZu1oZpmO8h7AvEIVUARgUI8OjLjsUC45qg8PjJ3DSTe+yEvTPip0sUSaVCGDw/vAQWbW1mJ66jHEXIfngDPTMV8BHi1Q+UQ+VV5Wyn+e0J/7v3EwpSXG+beN5su3jWbmR6sKXTSRJlHoSXDXAN8klshYA3yOuJ/D88TCe0uAfdx9o429mgQnzWnNulr+8tpsbnxmGtW1dVx61B78xxG7U15WWuiiiWyWFjsJjpjbcKW7lwNdgLeALwE/d/fWwK+BKwtYPpE8Fa1KufDw3Rn5nSM4buBOXP/0VE6+8UVGz/i40EUT2WoK2SFdBQwDbgNw97XuvpTopL4zHXYncHphSiiycV2rKrj53CHc/rUDqK6p4+xbX+N7D0xgySqt9irbvkLWHHYn5jncbmZvmtlwM2sH7OTu8wHSY9f6Emsoq7QUR+3ZlaevOIJvHNGHB8fN5ZjrX+DxtzSOQrZthQwOZcAQ4Hfuvh+xPPdVDU2soazSkrRpXcpVJ/Xn8csOo2enNlx695tcce94ln2iYa+ybSpkcJgDzHH30en3B4hgoYX3ZJs1oFsVD1x8CJcf25cRE+Zx0g2jePU99UXItqeQM6QXAB+Y2QAze5Poe5gMvEAsvDcNeAItvCfbmFalJVx+bD8evPgQyluVcu7w1/jp3ydTXVNb6KKJNFihRytdBjwF9AaqgJ+hhfekSAzu2ZG/f+swzvtML/744kxO++3LTJm/fNMJRVqAQgeHj4CpwBnAGOIe0lp4T4pG29Zl/OT0Qdz+1QP4aOVaTvvty9w66j3q6go3v0ikIQodHG4AvgfUpd87o4X3pAgd1b8rT15+OEfu2YWf/eMdzh3+GnOWrC50sUQ2qJDzHE4BFrr72OzN9RyqhfekKHSuLOcPX96fX5y5D2/PWcZJN7zI3aPfp1a1CGmBCllzOBQ41cxmAX8DjiZqElp4T4qWmfHFoT154vJhDOxexQ8efpvTb36ZsbOXFLpoIv+ikKOVvu/uPdy9N3Gr0Gfd/Ty08J5sB3ru0Ja/XXQQN54zmIUr1nDG717hO/dNYOGKNYUumghQwIX3zKwncBewM1ABrHL3vc1sP7TwnmxHVlXXcNOz07ntpRlUlJVyxXH9+OohvSkpqa+VVWTraakL79UA33H3AcA+QGszG4gW3pPtTLvyMq46qT9PXj6MIbt24urHJ3PBnW/w4XLVIqRwCtmsNN/dx6XnK4ApxMgkLbwn26Xdu1Ryx9cO4OrT9uKl6R9x1K+e5y+vzaaQy+rL9qvQQ1kBMLPewH7AaLTwnmzHzIx/O7g3I688kiG9OvHfj0zkq7e/wYJlqkVI8yp4cDCzSuBB4HJ3b/D0UQ1llWLWq3Nb7vr6gVx92l6MnvkxJ9wwihETNHBPmk9Bg4OZtSICw1/d/aG0WQvviQAlJVGL+Me3Dme3HdvxrXve5JK7x+l+EdIsCjkJzoh+hsOBr2ftegoYlRbeG0Usviey3dq9SyUPfONgvnt8P56cuIATtNKrNINCT4LrQyyR0cfMxpvZycSM6MwYPo3lEwHKSku49Oi+PHLJoVSWl3He8Nf4zchpml0tTaaQo5VecncjFtZ7z90Hu/s/gBOAw9PCe4cDJxaqjCItzd67dGDEZYdx6r7duf7pqXzlT6+zaEV1oYslRajgHdL10GglkY2oLC/j12cP5tozBvHGrMWc/JsXeWX6R4UulhSZlhgcADCzWWb2NtDezPKmP2u0kmzPzIyzD+jFo5ceSlVFGecOH80Fd7zBG7MWF7poUiRaYnD4dLQSsebSexua3i2yveu/cxUjLj2MK47tx5sfLOWs37/Kmb97hWcmf6h7RkijtMTgMIJYcA/gbLTwnshGtSsv49vH9uXl/zqa/zt1L+YvW8OFd43h9Fte5t0FKwpdPNlGFWzhPQAzuwc4EtgR+BD4X+AR4D5gGPAJMAO4xd1vzUl7EXARQK9evfafPXt28xVcpAVbV1vHiPHz+Nk/prBiTQ2XH9eXiw7fnbLSlngtKIW0sYX3ChocNsbMurv7PDPrCjwNXObuo+o7VquyiuT7eGU1P3p0Iv94ewH79uzIdWftwx5d2xe6WNKCtNRVWTcoLef9VzObQtzfYR5wYGFLJbJt6VxZzs3nDuGmL+3H7I9XcfJvXuLWUe9pboQ0SIsMDkAr4EdpOe+jiaanBq+7JCLBzPjcvt156ophHNEv7l/9xT+8yoxFKwtdNGnhWmpwALjZzCYAzwIz04+IbIGu7Su49cv7c8PZg5n24QpO/s2L/OmlmRrRJBvUUoPDfwPdgFLgs0AlsZz3pzQJTmTzmBmn77cLT195BIf02ZGrH5/MObe+xuyPVxW6aNICtcgOaTMbBqwE/kKMWPpp1qqtedQhLbJ53J0Hxs7h6scmU1PnfP/k/pz/mV11a9LtzDbXIZ1GJS0HevKvy3mLyFZgZpw1tCdPXTmMA3bbgf95dBLnDR/NB4tXF7po0kI0e3AwsxPN7F0zm25mV9Wz/6tmtggYA7RhAx3RalYSabxuHdpw59cO4JovDOLtucs48YZR3D36fd2aVJo3OJhZKXAzcBIwEPiSmQ2s59BRQAegBrg0aznvT2ltJZGtw8w458BePHH54Qzu1ZEfPPw2//an11WL2M41d83hQGC6u89w97XA34DT6jluPrBbOnZw1nLeItJEenRqy18u+Aw/OX1vxs5ewpG/ep6rH5usWsR2qrmDwy7AB1m/z0nbcp0B/BPomSbE5VGzksjWZ2acf9CuPPudIzl+4E786eWZfP+ht5k4d1mhiybNrLmDgwE9Mn0OwCnEnd+y9QDaAnsAVcB0M7sgNyM1K4k0nZ07VHDzuUP44tAe/O2NDzjlppe4+rHJVNfUFrpo0kyaOzjMIxbUy/Q5DCP6FbK9DHRz91bAJcRw29uatZQiQkmJ8Ysz9+WNHx7LVw/pzZ9ensnnb36FhcvXFLpo0gwKUXOA/NpCtnfcPdMTVgHoHogiBdSlfTk/PnUvbjlvCJPnL+eQa55l2ep1hS6WNLHmDg47A5OBd4FVwCKglZldbWanpmN+aWafmJkDPwTqrTWoz0GkeZ08qBvfOa4fNXXOvlc/xU0jp7F8jYJEsWrWGdJmdjbwR2Aw0Rk9HRjl7udnHdOb6Gu4GdgJGOTuG609aIa0SPNwd56c9CGX3TOOdbVOaYkxpFdHzvvMrpy+X31jS6QlK8gM6Q1MdqsC1rr7DKKJqRXweTMbnYJCxhvAIUA5cGNTlVFENo+ZceLeOzPp/07k3osO4uIj+rB41Vouv3c8c5d+UujiyVbUJMFhI5PdlgGtzWw34i5ulcRtQH8NXJuSZybFPQJ8x92/sYHXULOSSIG0LivhM7t35rsn7MltXzkAgL+9/n6BSyVbU1PVHDY02c2BV4AniWDwBvAxsBdwkpkZ8ANiNdajiP6HEfW9gIayirQMvXdsx2cHdeP2l2exdPXaQhdHtpKmCg67AJ41n2Fw2jaH6OfoR9yfYWfgXOB4YAnQGfg90eRUlfaPrO8FVHMQaTkuO2YPVlbXcNtLuu1KsWiq4FBK9BlkmpUOBjoSNYW+qVmpE3HyH0Y0K3UmahZTgX2I5bpvAa4zs6rcF1DNQaTl6L9zFScP2pmbnp3OaTe/zG9GTmPi3GVaemMbVtZE+VYRJ/p/EoFiDbCju9eY2aVEs9JOxBpKjxLzGdoCi4H9iIX3ylO6UqLZ6dUmKquIbAU//8I+DNi5ipHvLOTXz0zl+qenslNVOV3alxe6aEXta4fsxhn799jq+TbJUFYzOwe4m7j381iiyegpdz8l65ilwEJ372dmNwLfJO7+1g7YlahxnAMcBHR398U5r3ER0alNr1699p89e/ZWfx8ismUWrajm+XcX8uK0j1hVnbsIgmwtr874mKP7d+W35w7ZovQbG8ra6JqDmZ1IDDctBYa7+zVAH6IWMDxtXw0cY2ZzgB+7+/D02q3NbC1QSzRxOTAUuIfodygDZucGBohmJeBWiHkOjX0fIrL1dGlfzllDe3LW0HrXzZSt5Ojrnm+yvBvV57CRIasOrEkdz9cBHwHjge8Cx2WSp+PaA4NSWUrd/UHgQ6K28aC7997Aa6tDWkSkiTS2Q3pDQ1bfA6pSx/PpxHyGGcADRA3CiNrCkjT7eWj6fT8z60j0RzwKLNjQC6tDWkSk6TS2WenTIatE89FYYr2k54FpRMdzb2ApcCIwC6gjRiYtBXbJalaqI2oRPyBmTl8AmJmdB+zp7guzXzinz6GRb0NERLI1tuawsSGrnYATiCalMmLI6neJUUlONB21JQLC94hmJiOGtZ4AfB24Kx1zQu4Lq+YgItJ0GltzaMyQ1SUpjxVEzeEToKO7zzezqcSoJSdqFKcAf25kWUVEpIEaW3NYQVz5/zuwL9GEVAPg7v9IHdIrgNXuvgfwIBEIOgNribkMnYkZ0pXAcjNrB5xJ9EO8RwSHe3NfWB3SIiJNp0HBYQMrrML6Iau3Ec1EDhxhZjdm3Z+hDXEv6LVEv0NmyGof4sS/GHiIWGNpd+BOYASxBlNfYKS7P5RbJjUriYg0nU0Gh40MV4U0ZJXoJ/gL0XQ0H9jZ3Uek48qA84E9Wd+MVQrsBjxDNB/NI2oUBqwE/g0YDSxw95M3UC7VHEREmkhDag4HEv0D/yTu4jafGK4Kacgq8CXiKv/zwA7AcWm46mnAOuB24ImUpppYImMV0dE8mRi51JEY4XR4On4QUGFmreorlGoOIiJNpyHBoSfQj/U1h4HA3mnf+8QJ/WAiiDwLPE30H5ybjnNiiGs50SdRC3QgagyvErWFQ4hgMYdoZmpDdFx3AGaaWV7tQTUHEZGm05Dg0Je42s/UHJYSTUKwfshqNTCBWEtpL6LZ6AmiD+FjYEg6ZhWxVHdfYkmNA4ngMZ0IFq8DDxM1kvKU5j13/0duoVRzEBFpOg0drdSJ9TWHXsRVPe5eA1xKXOkPAa4Grkn5npi2tyP6FsqJkU1PpTyrgN8SNYd+wFx3r2V9EKolhr4eZGYX5BZINQcRkabTkOCQOSZ7cbtPn6er+nXAC+7+06z9mT4GI5qYjiJO+Iuz8rwZGEAMd12eti1w91OJeQ9vA79299tyC6Wag4hI02nIJLhaoinpSaK56ANgjZldDYxx9xHEnIX26a5vi4ngYMQJ/n2iJlDD+olv9eaZ9v3VzPYiahzvAj+pr1BaPkNEpOk0pObwHtCaGFk0gOgknuHu/5MCA8SV/8w00e16Iig40b/QgWiOOpFoWpq2oTxTXnen/R8AF7v7yvoKpZqDiEjTaUjNITMiKXOVPwWYmFNzmAR0z6o5rE2PbxMzoDM1h2nEiCTqyzNt/z0wm7jxz3Nmdr+7X93I9ykiIpuhIcEhMyLpGGBu+n2Eu0/KOuYRYJC7H5PuAvcFd3czG0HczW0g0B0YSYxIsvryBHD3MgAzmwUc5RniswUAAAyaSURBVO4fNfZNiojI5tlks1LWiKQniSv8+9x9kpldnbVExm1A51RzuBK4KqWdBNxH1ByeAC5x99oN5QlgZt9Kd4zrAbxlZsO33tsVEZGGaJJ7SDe3oUOH+pgxYwpdDBGRZnX0dc8zsFtVk9xDurGrsoqISBFScBARkTwKDiIikkfBQURE8ig4iIhIHgUHERHJo+AgIiJ5FBxERCSPgoOIiORRcBARkTwKDiIikkfBQURE8ig4iIhIHgUHERHJo+AgIiJ5FBxERCSPgoOIiORRcBARkTwKDiIikkfBQURE8ig4iIhIHgUHERHJo+AgIiJ5FBxERCSPgoOIiORRcBARkTwKDiIikkfBQURE8ig4iIhIHgUHERHJo+AgIiJ5FBxERCSPgoOIiORRcBARkTwKDiIikqes0AUQEZEtM6xvF3p0atMkeSs4iIhso3586l5NlrealUREJI+Cg4iI5FFwEBGRPAoOIiKSR8FBRETyKDiIiEgeBQcREcmj4CAiInnM3QtdhkYzs0XA7EKXYxu1I/BR1mPu9o0935zjNpW2oWk2Z1tD9zcm7ZYc25z5be6+zflsG/pdaMj+zc1Lto5d3b1LvXvcXT/b8Q8wJvsxd/vGnm/OcZtK29A0m7Otofsbk3ZLjm3O/DZ33+Z8tg39Lmzu96gheemn6X/UrCQiInkUHEREJI+Cg9ya85i7fWPPN+e4TaVtaJrN2dbQ/Y1JuyXHNmd+m7tvcz7bhn4XGrJ/c/OSJlYUHdIiIrJ1qeYgIiJ5FBxERCSPgsM2zsxONLN3zWy6mf1pA88npMfXzew1M1trZmvMbKmZuZnVmdlbZjYv7avJ2r4wbVtrZuvS9uyfGjNblY7N3rbCzBaZWXV6rcy+den3ajOba2bX5hyz2sweN7PJqUwjzWxXM/uqmX2S0n9iZhem99/TzJ4zsylmNsnMvl3PZzTLzN42s/Fm9lF6TxOz9u9gZk+b2UwzW5w+t0/zyto/LT12ykpbamZvmtnj6ffdzGx0OvZeM2ttZh3N7AEzeyeV8+AN5WlmV6TXnmhm95hZRU6e49L+SWZ2eU75FpnZyvQamX0/Tp/znPS5zc7a94v0d61Lj9eb2b7p+Dozq01/h++lvOvS5z/RzJZl/c3rzGxB+jtm0q1Jf8vc78XHFt+zlSmv2vSYyXtxVlk/zNl3i5m9mj7HWovvXeY93Z3+xlPMbEx6PsHMjmyyf75iV+ixtPrZ8h+gFHgP2B2oAKqB43OeX0ZMIBoI/AlYl45/CHDgZODn6fkHwJ3p+TvAk1nHfJyeP58eHXgKmALUAHXAcuB0oDblNRVYDHwCPApMByal8jwPzAUmAzPT8Q8B56TjhqT3eDFwL/DVtH8IMDHrM+iWdWz79JoDcz6nWcCO6fmwevL4BXBVyus3wLXZeWX2p2OvAq7NSnslcDfwePr9PuCc9Pz3qfx3Ahemba2BjvXlCeySPos2WXl9NZMnsHf6PL9F3MXxGaBvyuvXwETgR+n3zL4fA79K+9pmpTsZWE1MHm0PjAeWAe+y/rtzYXq9pelveBIwMqXx9Hc6Ov3taoEFwPyUzyLiO7Ei7XuM+J6sTu9xFjCB+A6sS2V8BliZ9n8+pasGBgG3p/TnAr2BtcCd6XP6AzApPb88vWZvoCswFigp9P/qtvijmsO27UBgurvPAPYj/mn3z3l+CnA/cBqQuafgTOAA4h98X+IfMnPCPwpYAzwHDEjHX0j8U0OcLOrS74cDd6XtDixy90dS+q5E4HAiiO1OnIBGAUuIE10F8E+giggSy4kTwG3ACSnf14Ae6fm89Pqfcvf57j4uPV+RXnOXDX1g7j4qN4/02dzp7vOJQHl6Tl6nESd40uPpAGbWA/gsMDz9bsTJ8oGsY88gAtJt6fXXuvvSDeVJnLzbmFkZcTKfn5XnAOAl4LPuXgO8QJxET0uf32upLKdl7YP4W7zm7quz0n2JOOFPT+91KrAK2A0w4Gni4qAMaEP8DZ8ggvrKlO9OxPdkAfF37kL8/eYQJ3wjLgQWE8GglAgcpUBnoDtxkl9GBKta4iKklPhulABvE0Hpd2l75rtQSnyHAd4CeqXPbO9UvuXuvpAIbEORzabgsG3bhbhqyzyflx5zn2dOct2IE3dn4uq1BuiTttcS/3CdiJP0uvS8FtgjvUbmBODEP7UTV2klxIlgFzP7dTq2jghOmXz3JE4G61LaGuJqdg7QIR17ItA/bcuc4C8gAgjEifafQE8z65n7YZhZbyIwjs7Z5cBTZjbWzC6q53PcKQUG0mPXnLzy9qd0NwDfS+8V4nNdmk7ApPfRm7iKvj01Pw03s3b15enuc4kr6PdZfwU+NivPicTJr5eZtSVOqD2Jk/RLRBBam8qX2QdwDPBlM/urmXVP+4z4Lgwzs3lEcCpLr+nAecRVeiVR26klajGnALumfFsRtYd+xN8Y4FmittUt6zPpzPrg1yWVbwnxHdwl7e+b3nvP9HM9cQGyb9r3Pyn9sPRowJ5m9kJ6vYr0mX2ZqI0sN7PdiO9V3ndFNk3BYdtm9Tz3Bj6nnu3kbK/vee4x5xAn+nVEbWUH4qTRGvgB8N/EFeli4sS/C1BOnBCuJK7sngceAd4gmgUqADez84mrvl8SzRK9iavIlay/6o43b1YJPAhc7u7Lc8p5qLsPSWkvIWpcm7KhvDKvdwqw0N3HZm/eQF5DgN+5+37EZ3HVBvLsRFz170YE0napzAC4+xTgFuJzeIJolqnJ2nctccVfmbXvd0Av4n0fDYxL+xYRFw1LiWallUQN4e9EcLoTuJoICuuIv98fiYC5MuVdQwSKSuK7UEKcnNewPshUps8lc8Vfl36vYH1NYhERmJ4gTuzvE7WaTG32QuCwlH4Q0bw4PJWtK/CVlG/39NnsTtQmbgBeyXxGsnkUHLZtc1h/VTSH+OeYV8/zAen5POKfMtOOXAbMSNtLiX+2JUQzT+v0PNOvAfFPvSg9tk4/nYgTnqf87kqPDvyZaO6oSOkWECeTXinNOGBnYFp6Hx8DHxJXi22AHwKnunu1u3/s7tWpHEuIK8IolFkr4mT+V3d/KPdDcvd56XEh8HDKP9uHZtYt5dUzva/svLL3dwMWAocCp5rZLOBvxIn3BqBjat6AOCF+AMxx90xt5gEiWNSX57HATHdf5O7riJPgITl5vgyMcvdhxN9xWiYvd7+NaOaakdnn7h+6e627DwcOZn0zzzSiWaaru7cn+kcqgNfdva+7lxIn4iXAPHffxd3LiKv7acBcd69M294kapvTib6BcamcM1O+Pwd+SwSZD9Lf4DBgDBFwbiECFkRgeJWo0dal17sE+GJKf20K9L8Cxrv7AOK7tMjd16Va2CPAj939NKJ2Mg3ZbAoO27Y3gL6p+jyeOPGOzXn+d+AsYARxooa4uhpLnOQnsP7qroRoQ64g+h7eSccPJ9q/SY8l6XElETzWEQGhM3EyMCLgtCWaHNYSJ6zexAmnmjh5tCKaL/5ANB10JYLFiUSH6KnphJ45gWa0J656M+38twFT3P363A/IzNqZWfvM85Tv1JzDRgBfSXk9Wk9eI4irU9Ljo+7+fXfv4e69idrTs+5+Xvr8zsw69n7gAzPbM207hvg75OVJnBgPMrO2qSyZY7Pz/A/gUTPrBXwBuCer/Jmr6Gcz+7ICUFeiD2JGVroPgdNSXl8hLg6eNrOBZlZCnNQrgd+nbb2Ik/S+wH1m1tXM+gODiYAzgvjeDCUuDpYRQeMcolmpmrgI+BXwE6Km8AWiJjeFaEY6kKgpHk1cTJxFDEj4I1GbuCe9l5+kcvUhLlA+sLAjEQTfMbPjgBp3z3zvZXMUukdcP437IdqPpxJX93eyfoTQyPR8CdEZOJ2osk8jTtbZVX8nmoTmEyeI2rQt0/Gc3U/gOT819WyvJU4KtSndupz91axvinowlT37NauJE9cC4mQ2gjhRLUtp6tK+C4grUCeaEcann5OzPp/diQA4gRgpNSG9z3VEreoCIqiNJK5qPR33aV5Z+6elxx1y/gZHsn600u7A6+nzvp9oQhtMXCW/RVzVdtpQnsD/EUF5IlHzKs/JM9McNAE4JqXJ5PUJcRU9MWvfn4lO3VVE/9CkrH0T0udel9J+A/g26/uTaogg8mLWtrXp71Gd8/fO/E0zf8O6rDTZ35WFxHevjvXfjzrWfy/msn5U04qsfauI2sdU4sJjZTp+DVETuT+9t2npNaYQo592LfT/6Lb6o+UzREQkj5qVREQkj4KDiIjkUXAQEZE8Cg4iIpJHwUFERPIoOIiISB4FBxERyfP/Addmtph//wwGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bob.measure as bm\n",
    "\n",
    "positives = trials_results.loc[trials_results['Targettype'] == 1]\n",
    "negatives = trials_results.loc[trials_results['Targettype'] == 0]\n",
    "\n",
    "#neg_array = negatives['Score for actual']\n",
    "#print(neg_array)\n",
    "print(np.max(positives['Score for actual']))\n",
    "print(np.max(negatives['Score for actual']))\n",
    "eer=bm.eer_rocch(negatives['Score for actual'], positives['Score for actual'])\n",
    "print(eer)\n",
    "bm.plot.det(negatives['Score for actual'],positives['Score for actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "lstm.weight_ih_l0 \t torch.Size([16, 40])\n",
      "lstm.weight_hh_l0 \t torch.Size([16, 4])\n",
      "lstm.bias_ih_l0 \t torch.Size([16])\n",
      "lstm.bias_hh_l0 \t torch.Size([16])\n",
      "hidden2label.weight \t torch.Size([1251, 4])\n",
      "hidden2label.bias \t torch.Size([1251])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tellurium/anaconda3/envs/python3/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LSTM. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, \"first_iteration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
